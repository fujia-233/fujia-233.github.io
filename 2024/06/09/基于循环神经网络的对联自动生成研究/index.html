<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><title>基于循环神经网络的对联自动生成研究 | 附加</title><meta name="keywords" content="作业,深度学习,循环神经网络"><meta name="author" content="附加"><meta name="copyright" content="附加"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#f7f9fe"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="基于循环神经网络的对联自动生成研究"><meta name="application-name" content="基于循环神经网络的对联自动生成研究"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#f7f9fe"><meta property="og:type" content="article"><meta property="og:title" content="基于循环神经网络的对联自动生成研究"><meta property="og:url" content="http://example.com/2024/06/09/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/index.html"><meta property="og:site_name" content="附加"><meta property="og:description" content="基于循环神经网络的对联自动生成研究一、概述1.1 选题背景及意义​		深度学习的概念最早由 Geoffrey Hinton 在 2006 年提出，其兴起于图像识别领域，在之后的很短时间内，深度学习技术广泛应用于机器学习的各个领域。在AI领域中，自然语言处理（Natural Language Proc"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="http://example.com/images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/cover.jpg"><meta property="article:author" content="附加"><meta property="article:tag" content="java 雅思 英语"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="http://example.com/images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/cover.jpg"><meta name="description" content="基于循环神经网络的对联自动生成研究一、概述1.1 选题背景及意义​		深度学习的概念最早由 Geoffrey Hinton 在 2006 年提出，其兴起于图像识别领域，在之后的很短时间内，深度学习技术广泛应用于机器学习的各个领域。在AI领域中，自然语言处理（Natural Language Proc"><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="http://example.com/2024/06/09/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/"><link rel="preconnect" href="//cdn.cbd.int"/><meta name="google-site-verification" content="xxx"/><meta name="baidu-site-verification" content="code-xxx"/><meta name="msvalidate.01" content="xxx"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/swiper/swiper.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  linkPageTop: undefined,
  peoplecanvas: undefined,
  postHeadAiDescription: undefined,
  diytitle: {"enable":true,"leaveTitle":"w(ﾟДﾟ)w 不要走！再看看嘛！","backTitle":"♪(^∇^*)欢迎肥来！"},
  LA51: undefined,
  greetingBox: {"enable":true,"default":"晚上好👋","list":[{"greeting":"晚安😴","startTime":0,"endTime":5},{"greeting":"早上好鸭👋, 祝你一天好心情！","startTime":6,"endTime":9},{"greeting":"上午好👋, 状态很好，鼓励一下～","startTime":10,"endTime":10},{"greeting":"11点多啦, 在坚持一下就吃饭啦～","startTime":11,"endTime":11},{"greeting":"午安👋, 宝贝","startTime":12,"endTime":14},{"greeting":"🌈充实的一天辛苦啦！","startTime":14,"endTime":18},{"greeting":"19点喽, 奖励一顿丰盛的大餐吧🍔。","startTime":19,"endTime":19},{"greeting":"晚上好👋, 在属于自己的时间好好放松😌~","startTime":20,"endTime":24}]},
  twikooEnvId: 'https://lucent-phoenix-95de8f.netlify.app/.netlify/functions/twikoo',
  commentBarrageConfig:undefined,
  music_page_default: "nav_music",
  root: '/',
  preloader: {"source":3},
  friends_vue_info: undefined,
  navMusic: true,
  mainTone: undefined,
  authorStatus: {"skills":["🤖️ 数码科技爱好者","🔍 分享与热心帮助","🏠 美食文化探索者","🔨 奇妙世界观察者","想养一只小猫咪 🤝","脚踏实地行动派 🏃","团队小组发动机 🧱","壮汉人狠话不多 💢"]},
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简","rightMenuMsgToTraditionalChinese":"转为繁体","rightMenuMsgToSimplifiedChinese":"转为简体"},
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":330},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    simplehomepage: true,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"copy":true,"copyrightEbable":false,"limitCount":50,"languages":{"author":"作者: 附加","link":"链接: ","source":"来源: 附加","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","copySuccess":"复制成功，复制和转载请标注本文地址"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#425AEF","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  shortcutKey: undefined,
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  configTitle: '附加',
  title: '基于循环神经网络的对联自动生成研究',
  postAI: '',
  pageFillDescription: '基于循环神经网络的对联自动生成研究, 一、概述, 1.1 选题背景及意义, 1.2 开发团队, 1.3 开发环境, 1.4 国内外研究现状, 二、相关理论及其技术介绍, 2.1 循环神经网络, 2.1.1 标准循环神经网络, 2.1.2 长短时记忆网络, 2.2 注意力机制, 2.3 序列到序列模型, 2.3.1 经典的序列到序列模型, 2.3.2 基于注意力机制的序列到序列模型, 三、对联生成模型设计, 3.1 Encoder-Decoder 框架结构简介, 3.1.1 输入处理, 3.1.2 编码阶段, 3.1.3 解码阶段, 3.2 数据处理部分, 3.2.1 噪声数据摘除, 3.2.2 添加输入开始与结束标志, 3.2.3 建立词库与字典, 3.2.4 数据向量化, 3.2.5 数据集划分及封装, 四、模型训练, 4.1 参数设定, 4.2 模型训练, 4.3 模型预测, 4.4 展示界面搭建, 五、模型评测, 5.1 loss曲线, 5.2 困惑度, 六、结语, 七、参考文献基于循环神经网络的对联自动生成研究一概述选题背景及意义深度学习的概念最早由在年提出其兴起于图像识别领域在之后的很短时间内深度学习技术广泛应用于机器学习的各个领域在领域中自然语言处理是一个占据着极其重要地位的子领域它的发展可以使计算机理解和利用人类语言使计算机达到认知智能并逐步迈入感知智能主要包括语言理解和语言生成两大部分在语言生成范畴诗歌和对联的自动生成是一个非常重要的分支具有很强的前瞻性一直是学术界研究的热点在本文中我们研究了对联的自动生成我们提出了一个基于注意力的编码器解码器模型来接收前从句并在对联对中输出后续子句给定任何指定的先行从句我们学习单个字符的表示以及从句中的组合以及它们如何相互加强和约束我们可以使用编码器解码器模型生成后续子句在生成过程中我们结合了注意力机制以满足对联的特殊性使用深度神经网络进行对联的生成研究是一项十分具有意义的工作对联的自动生成也是对自然语言处理领域中一个具体方面的深入探索和研究对自然语言处理领域内的其他任务也有一定的借鉴参考价值使用机器学习方法进行对联的创作可以将其生成方法拓宽到其他场景下促进中国传统文化的传播和发展开发团队组员富佳夏取明王艺凡具体分工富佳组长数据集整理预处理展示界面搭建报告撰写夏取明模型搭建训练及模型预测参考文献收集王艺凡数据集搜集参考文献收集报告撰写开发环境操作系统型号型号内存主要工具国内外研究现状在以往的研究中很少有研究关注深度学习对中国对联的应用但有类似的文本分类识别应用在机器翻译和欧美古典诗歌自动生成等方面机器翻译的概念始于年年美国实验室第一次完成英语和俄语间的机器翻译实验证明了机器翻译的可行性但是在后面一段时间内由于速度慢消耗计算资源高准确性低等缺点机器翻译的发展一度停滞直到世纪年代随着社会信息服务需求的扩大机器翻译技术在处理大量文本翻译任务的优势逐渐凸显机器翻译的研究开始复苏古典诗歌自动生成的研究始于年当时通过计算机创作了第一首德语诗歌从那时起机器自动生成诗歌从简单的词堆栈方法开始然后逐渐发展到现在的基于案例的推理方法以及其他新兴的方法可分为基于模板的生成方法基于遗传算法的方法生成和测试方法以及基于案例的推理方法很少有研究关注中国对联的产生中国对联生成任务可以看作是两句诗生成的简化形式给定诗的第一行生成器应该相应地生成第二行这与对联生成的过程类似但是对联生成和诗歌生成之间仍然存在一些差异生成后续从句以匹配给定的前置从句的任务比生成一首诗的所有句子更明确此外并不是诗中所有的句子都需要遵循对联的约束总的来说国内基于的对联自动生成系统在技术上已经取得了一定的进展但仍面临着诸多挑战如语义理解语法结构韵律要求等未来随着深度学习技术的不断发展和对联生成应用场景的不断拓展这些挑战将逐渐得到解决对联生成系统的性能和应用前景也将不断提升二相关理论及其技术介绍循环神经网络标准循环神经网络基础的神经网络包括输入层隐藏层和输出层三层结构其只在层与层之间建立连接而标准循环神经网络在此基础上在同层之间的神经元之间也建立了连接的神经网络结构如图所示等号右边为神经网络按时间展开图等号左边是其简化图长短时记忆网络长短时记忆网络是循环神经网络的一个最常见的扩展模型其就是为了解决一般网络的缺陷更有效的应对产期依赖问题的隐藏层比更为复杂采用了三个门结构用来解决长期依赖问题如图所示的隐藏层分别包含了输入门遗忘门和输出门这是最基本的结构目前有的变种形式如等等但是基本思想都是统一的和是目前比较常见的神经网络隐藏层单元结构除此以外还有提出的结构提出的结构等对于具体的任务可以适当变形以适应任务需要注意力机制注意力机制简称最早的提出是在图像领域受到人类注意力机制的启发人类观察图像时往往有重点的将注意力集中在图像的特定部分并且会根据之前观察图像的经验来观察之后的图像基于注意力机制的文本分类机制为每个词赋予了权重并根据权重生成语义编码其编码的三个阶段具体计算步骤为计算和不同的相关性计算不同值的权重系数对上一阶段的输出进行归一化处理将数值的范围映射到和之间根据权重系数对进行加权求和从而得到最终的注意力数值在注意力模型中由于每一次输出的词语在计算的时候使用到的语义编码都是不一样的这也体现出注意力的意义在很多任务中都已经取得了很好的效果序列到序列模型经典的序列到序列模型序列到序列模型亦称为编码解码模型由谷歌公司于年在论文中提出序列到序列模型的提出在整个深度学习领域获得了很大的影响近年来在机器翻译语音识别图像识别文本生成等领域的大部分研究都是围绕序列到序列的模型框架展开如图所展示了一个经典的序列到序列模型模型包含了一个编码器和一个解码器编码器的作用是提取输入序列特征并将其压缩成一个固定大小的语义向量解码器的作用是解读语义向量将其转化为目标输出序列其中编码器和解码器一般采用循环神经网络基于注意力机制的序列到序列模型经典的序列到序列模型在很多问题上都非常有效但是也存在问题最大的不足在于编码器和解码器仅通过一个固定的语义向量进行联系每个输出时刻语义向量的值都是不变的且语义向量并不能够将整个序列的信息完全表示如此解码器在每个时刻仅根据历史的信息和固定的语义向量进行输出这样会导致本应该和输出强相关的输入信息被严重的稀释了因此将注意力机制应用于序列到序列模型如图展示了基于注意力机制的序列到序列模型示意图用经典的序列到序列模型结合注意力机制使得编码器和解码器之间通过一个可变的语义向量进行联系每个输出时刻语义向量都是不同的可变的表示了每个时刻输出最相关的输入信息本文主要用到基于注意力机制的序列到序列模型因此这里展开描述基于注意力机制的序列到序列模型计算过程步骤假设基于注意力机制的序列到序列模型输入的源序列为输出的目标序列为那么在第时刻模型的输出计算过程可以表示如下其中不是一个固定的值会根据每一个时刻的变化而变化由编码器的隐藏向量通过如下公式计算得到其中为注意力权值计算公式如下其中其中表示解码器第时刻的隐藏层状态函数表示计算和的相似度首先计算解码器隐藏层状态和编码器隐藏层状态的相似度然后对计算出的相似度采用类函数进行归一化得到注意力权值最后注意力权值与编码器隐藏状态相乘求和得到语义向量三对联生成模型设计框架结构简介对联生成问题为典型的序列生成问题这里采用最经典的框架结构由于预测句子中下一个词一般需要用到前面已经生成的词前后词语之间并不是独立的同层节点之间相互连接能够体现这种前后词语之间的联系并且同层节点之间的权值是共享的因此本文任务选择使用一般的结构需要将输入压缩成一个固定长度的向量这就很难处理一些比较长的句子特别是那些比训练集中语句更长的语句本文在编码阶段采用的是双向结构这在语音识别方面已经得到了很有效的应用解码阶段选择的就是结构为了在每次生成输出词语的时候充分利用输入序列携带的信息使输入序列中的不同词语对输出词语有不同的影响本文在解码阶段使用了注意力机制另外为了体现上下联语句在语义和语境上的一致性本文在解码的时候将含有上联整句信息的句向量考虑进去下图是本文建立的对联生成模型的总体结构图输入处理本文任务的基本模式就是输入上联输出对应的下联这里的输入上联是汉字组成的序列很显然将这个任务转化为深度学习问题必须将上联的文字符号化输入计算机中第一步任务就是将序列中汉字转化为一个向量就是所谓的词向量一般的词向量在训练时只考虑到词语与其所在训练序列中的前后词语之间的关系由于对联任务的特殊性不仅需要考虑前后词语之间的关系还需要考虑上下联中对应位置的词语之间的联系于是在训练词向量的时候将上下联对应位置的字考虑在内也就是将其加入上下文中将训练出来的这种词向量称之为对联字向量编码阶段为了体现序列前后词语之间的联系在编码阶段本文使用的是的结构门控循环单元神经网络简称是由等人在年提出来的是的衍生物属于的一种变种与的结构本质上并没有什么不同差异在于计算隐藏层状态的函数使用了更新门与重置门来控制标准的梯度消失的问题这两个门控向量基本上决定了最终输出哪些信息这两门控机制能够保存长期序列中的信息且不会随着时间变长而被清除或因与预测不相关而被移除本文中编码阶段使用的是双向的由图可以看出一个前向的一个反向的正向的和反向的实际上并没有什么区别只是输入序列的顺序不同解码阶段解码阶段的任务是根据输入的中间语义表示以及前面生成的历史信息来生成时刻要输出的词语前面说过解码阶段使用的依然是的变体在基础的中每个都一模一样的并不能加强或者减轻某个字对某个词的作用大小很明显上联中对应位置的字对当前字生成的影响较大其他位置的字对当前字生成的影响较小为了解决这个问题体现出上联中不同字对于下联中不同词语的影响在解码过程中应用了机制模型可以说是今年来领域中的重要进展之一其效果在很多场景得到证实在中加入后在生成每一个的时候的中间语义向量都是不相同的是根据当前生成字而不断变化的数据处理部分噪声数据摘除数据集来源此数据集包含了五个文件将文件按照的顺序进行合并之后发现有条数据有问题其中前个问题为上联后个问题为下联经过对噪声数据进行处理后最终获得条对联数据添加输入开始与结束标志表示一个输入的开始表示一个输入的结束建立词库与字典在字典的创建过程中主要先用一个辅助字典存储每个词汇出现的频率然后根据频率排序辅助字典然后初始化两个字典遍历辅助字典可用当前字典非辅助字典的长度作为词汇数字标识在该过程中我们还可以根据频率筛选出频率大于一定阈值的词汇即抛弃低频词汇词库由上下联所有字符可用列表表示字典建立词汇向量向量词汇两个字典向量在这里可以理解为数字化最终的目的是向量化数据向量化根据前一步中创建的词汇向量字典将所有数据向量化数据集划分及封装我们总的数据为条按照的方式划分训练集验证集测试集数据集的封装主要使用以及提供的方法其中主要是进行每个数据的操作统一长度最终我们得到封装好的训练集验证集测试集以训练集为例每个元素包括五部分上联输入向量输入向量未填充前的长度用于控制的隐藏状态是否更新填充位置下联输入向量不包含最后一个位置的元素下联输入向量不包含第一个元素然后在最后一个扩维用于计算下联输入向量的向量四模型训练参数设定的层数隐藏层的状态数嵌入层的维度学习率每个输入一次日志信息梯度裁剪优化器不是参数在这里我们把他看作一个参数损失函数使用的是带掩码的交叉熵损失函数评价准则困惑度模型训练部分关键代码使用函数进行训练及验证部分参数设置模型预测模型的预测使用了束搜索常规的搜索方法有贪心搜索和穷举搜索穷举搜索穷举所有可能的输出结果例如输出序列长度为候选项为那么就有种可能当输出序列长度为时就会有种可能这种幂级增长对于计算机性能的要求是极高的耗时耗力贪心搜索每次选择概率最大的候选者作为输出搜索空间小以局部最优解期望全局最优解无法保证最终结果是做优的但是效率高束搜索束搜索可以看作是穷举搜索和贪心搜索的折中方案需要设定一个束宽当设为时即为贪心搜索当设为候选项的数量时即为穷举搜索展示界面搭建展示界面使用自带的包进行搭建主要包括两个文本框和两个动作按钮用户输入对联的上联然后点击相应按钮系统会提取用户的输入将其向量化然后送入训练好的模型中产生输出然后显示在另一个文本框中五模型评测曲线曲线数据由提供的接口在训练时保存在文件中之后通过可视化工具进行展示横轴表示训练的纵轴表示值通过训练集与验证集的曲线可以看出训练在前期收敛较快训练集后期有波动但是验证集后期仍为缓慢下降趋势说明模型的训练效果是不错的困惑度困惑度数据的获取方式同通过训练集与验证集的困惑度曲线任务模型训练效果可以但是训练集的困惑度后期呈现为直线这应该是存在问题的有待分析解决我们在测试集上进行了困惑度分析每个的数据困惑度基本一致说明模型波动较小效果理想六结语对联是中华文化一种独特的艺术形式其上下联之间讲究对仗工整平仄协调这要求对联创作者具备丰富的知识储备和深厚的文学素养因此创作对联对普通人来说稍显困难对于计算机来说在自然语言处理领域对联的生成也是一项比较困难的任务近年来深度学习技术快速发展在如图像识别语音识别等机器学习领域表现出色自然语言处理作为机器学习的重要分支深度学习技术也推动着自然语言处理技术不断发展本文首先讨论了自动生成对联的研究背景和研究意义以及对联生成模型的国内外研究现状介绍了循环神经网络和注意力机制并且采用基于注意力机制的序列到序列模型对对联生成系统进行进一步研究掌握了基于编码解码框架的神经网络模型注意力机制模型等算法明确研究方向舍弃了传统的基于循环神经网络或卷积神经网络的方法完全使用注意力机制的神经网络结构进行对联的自动生成结果表明注意力机制在对联的自动生成任务上具有不可替代的作用七参考文献王治权基于注意力机制和改进型的文本情感分析研究王哲基于深度学习技术的中国传统诗歌生成方法研究中国科学技术大学蒋锐滢崔磊何晶等基于主题模型和统计机器翻译方法的中文格律诗自动生成计算机学报',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-06-09 00:00:00',
  postMainColor: '',
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.3.0"></head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" alt="加载头像" src="/img/touxiang.jpg"/><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.getElementById('loading-box').classList.add("loaded");
  },
  initLoading: () => {
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })
setTimeout(function(){preloader.endLoading();},10000)

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.10/progress_bar/progress_bar.css"/><script async="async" src="https://cdn.cbd.int/pace-js@1.2.4/pace.min.js" data-pace-options="{ &quot;restartOnRequestAfter&quot;:false,&quot;eventLag&quot;:false}"></script><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><div class="back-home-button"><i class="anzhiyufont anzhiyu-icon-grip-vertical"></i><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://fujia-233.github.io" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/images/touxiang.jpg" alt="博客"/><span class="back-menu-item-text">博客</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">我的</div><div class="back-menu-list"><a class="back-menu-item" href="/album/" title="相册集"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/images/1.jpg" alt="相册集"/><span class="back-menu-item-text">相册集</span></a><a class="back-menu-item" href="/bangumis/" title="追番页"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/images/2.jpg" alt="追番页"/><span class="back-menu-item-text">追番页</span></a><a class="back-menu-item" href="/music/?id=893451151&amp;server=netease" title="音乐馆"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/images/3.jpg" alt="音乐馆"/><span class="back-menu-item-text">音乐馆</span></a></div></div></div></div><a id="site-name" href="/" accesskey="h"><div class="title">附加</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a><div id="he-plugin-simple"></div><script>var WIDGET = {
  "CONFIG": {
    "modules": "0124",
    "background": "2",
    "tmpColor": "FFFFFF",
    "tmpSize": "16",
    "cityColor": "FFFFFF",
    "citySize": "16",
    "aqiColor": "E8D87B",
    "aqiSize": "16",
    "weatherIconSize": "24",
    "alertIconSize": "18",
    "padding": "10px 10px 10px 10px",
    "shadow": "0",
    "language": "auto",
    "borderRadius": "20",
    "fixed": "true",
    "vertical": "top",
    "horizontal": "left",
    "left": "20",
    "top": "7.1",
    "key": "df245676fb434a0691ead1c63341cd94"
  }
}
</script><link rel="stylesheet" href="https://widget.qweather.net/simple/static/css/he-simple.css?v=1.4.0"/><script src="https://widget.qweather.net/simple/static/js/he-simple.js?v=1.4.0"></script></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 归档</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/essay/"><span> 随记</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/comments/"><span> 留言板</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/about/"><span> 关于我</span></a></div></div></div><div id="nav-right"><div class="nav-button only-home" id="travellings_button" title="随机前往一个开往项目网站"><a class="site-page" onclick="anzhiyu.totraveling()" title="随机前往一个开往项目网站" href="javascript:void(0);" rel="external nofollow" data-pjax-state="external"><i class="anzhiyufont anzhiyu-icon-train"></i></a></div><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="随机前往一个文章" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><input id="center-console" type="checkbox"/><label class="widget" for="center-console" title="中控台" onclick="anzhiyu.switchConsole();"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png" target="_blank"><img class="post-qr-code-img" alt="微信" src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png" target="_blank"><img class="post-qr-code-img" alt="支付宝" src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"><div class="console-card" id="card-newest-comments"><div class="card-content"><div class="author-content-item-tips">互动</div><span class="author-content-item-title"> 最新评论</span></div><div class="aside-list"><span>正在加载中...</span></div></div></div><div class="console-card-group-right"><div class="console-card tags"><div class="card-content"><div class="author-content-item-tips">兴趣点</div><span class="author-content-item-title">寻找你感兴趣的领域</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/Java/" style="font-size: 1.05rem;">Java<sup>2</sup></a><a href="/tags/Nginx/" style="font-size: 1.05rem;">Nginx<sup>1</sup></a><a href="/tags/Typora/" style="font-size: 1.05rem;">Typora<sup>1</sup></a><a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" style="font-size: 1.05rem;">人工智能<sup>6</sup></a><a href="/tags/%E4%BD%9C%E4%B8%9A/" style="font-size: 1.05rem;">作业<sup>8</sup></a><a href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/" style="font-size: 1.05rem;">决策树<sup>1</sup></a><a href="/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 1.05rem;">循环神经网络<sup>1</sup></a><a href="/tags/%E6%8A%80%E6%9C%AF/" style="font-size: 1.05rem;">技术<sup>2</sup></a><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 1.05rem;">深度学习<sup>2</sup></a><a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 1.05rem;">算法<sup>1</sup></a><a href="/tags/%E8%AE%BA%E6%96%87/" style="font-size: 1.05rem;">论文<sup>1</sup></a></div></div><hr/></div></div><div class="console-card history"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>文章</span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/12/"><span class="card-archive-list-date">十二月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/06/"><span class="card-archive-list-date">六月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">3</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/05/"><span class="card-archive-list-date">五月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">3</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/04/"><span class="card-archive-list-date">四月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/03/"><span class="card-archive-list-date">三月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/12/"><span class="card-archive-list-date">十二月 2020</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li></ul></div><hr/></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" title="显示模式切换" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="边栏显示控制"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div><div class="console-btn-item" id="consoleMusic" onclick="anzhiyu.musicToggle()" title="音乐开关"><a class="music-switch"><i class="anzhiyufont anzhiyu-icon-music"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" title="切换"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">原创</a><span class="post-meta-categories"><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%B6%AF/" itemprop="url">大学生涯</a></span><span class="article-meta tags"><a class="article-meta__tags" href="/tags/%E4%BD%9C%E4%B8%9A/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>作业</span></a><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>深度学习</span></a><a class="article-meta__tags" href="/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>循环神经网络</span></a></span></div></div><h1 class="post-title" itemprop="name headline">基于循环神经网络的对联自动生成研究</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="anzhiyufont anzhiyu-icon-calendar-days post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" itemprop="dateCreated datePublished" datetime="2024-06-08T16:00:00.000Z" title="发表于 2024-06-09 00:00:00">2024-06-09</time><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-history post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" itemprop="dateCreated datePublished" datetime="2024-06-08T16:00:00.000Z" title="更新于 2024-06-09 00:00:00">2024-06-09</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-wordcount"><i class="anzhiyufont anzhiyu-icon-file-word post-meta-icon" title="文章字数"></i><span class="post-meta-label" title="文章字数">字数总计:</span><span class="word-count" title="文章字数">5.8k</span><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-clock post-meta-icon" title="阅读时长"></i><span class="post-meta-label" title="阅读时长">阅读时长:</span><span>18分钟</span></span><span class="post-meta-separator">       </span><span class="post-meta-position" title="作者IP属地为燕郊"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>燕郊</span><span class="post-meta-separator"></span><span class="post-meta-commentcount"><i class="anzhiyufont anzhiyu-icon-comments post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2024/06/09/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/#post-comment" tabindex="-1"><span id="twikoo-count"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></a></span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section><div id="post-top-cover"><img class="nolazyload" id="post-top-bg" src="/images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/cover.jpg"></div></header><main id="blog-container"><div class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container" itemscope itemtype="http://example.com/2024/06/09/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/"><header><a class="post-meta-categories" href="/categories/%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%B6%AF/" itemprop="url">大学生涯</a><a href="/tags/%E4%BD%9C%E4%B8%9A/" tabindex="-1" itemprop="url">作业</a><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" tabindex="-1" itemprop="url">深度学习</a><a href="/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" tabindex="-1" itemprop="url">循环神经网络</a><h1 id="CrawlerTitle" itemprop="name headline">基于循环神经网络的对联自动生成研究</h1><span itemprop="author" itemscope itemtype="http://schema.org/Person">附加</span><time itemprop="dateCreated datePublished" datetime="2024-06-08T16:00:00.000Z" title="发表于 2024-06-09 00:00:00">2024-06-09</time><time itemprop="dateCreated datePublished" datetime="2024-06-08T16:00:00.000Z" title="更新于 2024-06-09 00:00:00">2024-06-09</time></header><h1 id="基于循环神经网络的对联自动生成研究"><a href="#基于循环神经网络的对联自动生成研究" class="headerlink" title="基于循环神经网络的对联自动生成研究"></a><strong>基于循环神经网络的对联自动生成研究</strong></h1><h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><h3 id="1-1-选题背景及意义"><a href="#1-1-选题背景及意义" class="headerlink" title="1.1 选题背景及意义"></a>1.1 选题背景及意义</h3><p>​		深度学习的概念最早由 Geoffrey Hinton 在 2006 年提出，其兴起于图像识别领域，在之后的很短时间内，深度学习技术广泛应用于机器学习的各个领域。在AI领域中，自然语言处理（Natural Language Processing，NLP）是一个占据着极其重要地位的子领域，它的发展可以使计算机理解和利用人类语言，使计算机达到认知智能，并逐步迈入感知智能[1]。NLP主要包括语言理解和语言生成两大部分。在语言生成范畴，诗歌和对联的自动生成是一个非常重要的分支，具有很强的前瞻性，一直是学术界研究的热点。</p>
<p>​		在本文中，我们研究了对联的自动生成。我们提出了一个基于注意力的编码器-解码器模型来接收前从句，并在对联对中输出后续子句。给定任何指定的先行从句，我们学习单个字符的表示，以及从句中的组合，以及它们如何相互加强和约束。我们可以使用编码器解码器模型生成后续子句。在生成过程中，我们结合了注意力机制，以满足对联的特殊性。</p>
<p>​		使用深度神经网络进行对联的生成研究是一项十分具有意义的工作，对联的自动生成，也是对自然语言处理领域中一个具体方面的深入探索和研究，对自然语言处理领域内的其他任务也有一定的借鉴参考价值；使用机器学习方法进行对联的创作，可以将其生成方法拓宽到其他场景下，促进中国传统文化的传播和发展。</p>
<h3 id="1-2-开发团队"><a href="#1-2-开发团队" class="headerlink" title="1.2 开发团队"></a>1.2 开发团队</h3><p><strong>组员：</strong></p>
<p>富佳、夏取明、王艺凡</p>
<p><strong>具体分工：</strong></p>
<p>富佳：组长；数据集整理，预处理；展示界面搭建；报告撰写</p>
<p>夏取明：模型搭建训练及模型预测； 参考文献收集</p>
<p>王艺凡：数据集搜集；参考文献收集；报告撰写</p>
<h3 id="1-3-开发环境"><a href="#1-3-开发环境" class="headerlink" title="1.3 开发环境"></a>1.3 开发环境</h3><table>
<thead>
<tr>
<th align="center">操作系统</th>
<th align="center">Windows</th>
</tr>
</thead>
<tbody><tr>
<td align="center">CPU型号</td>
<td align="center">AMD Ryzen 5 4600U with Radeon Graphics</td>
</tr>
<tr>
<td align="center">GPU型号</td>
<td align="center">AMD  Radeon(TM) Graphics</td>
</tr>
<tr>
<td align="center">内存</td>
<td align="center">16.0 GB</td>
</tr>
<tr>
<td align="center">主要工具</td>
<td align="center">Anaconda、Python3.6、paddle</td>
</tr>
</tbody></table>
<h3 id="1-4-国内外研究现状"><a href="#1-4-国内外研究现状" class="headerlink" title="1.4 国内外研究现状"></a>1.4 国内外研究现状</h3><p>​		在以往的研究中很少有研究关注深度学习对中国对联的应用，但有类似的文本分类识别应用在机器翻译和欧美古典诗歌自动生成等方面。机器翻译的概念始于 1949 年，1954 年美国 Georgetown-IBM 实验室第一次完成英语和俄语间的机器翻译实验，证明了机器翻译的可行性。但是在后面一段时间内，由于速度慢、消耗计算资源高、准确性低等缺点，机器翻译的发展一度停滞。直到 20 世纪 80 年代，随着社会信息服务需求的扩大，机器翻译技术在处理大量文本翻译任务的优势逐渐凸显，机器翻译的研究开始复苏。</p>
<p>​		古典诗歌自动生成的研究始于 1959 年，当时 Theo Lutz 通过计算机创作了第一首德语诗歌。从那时起，机器自动生成诗歌从简单的词堆栈方法开始，然后逐渐发展到现在的基于案例的推理方法以及其他新兴的方法，可分为基于模板的生成方法、基于遗传算法的方法、生成和测试方法以及基于案例的推理方法。很少有研究关注中国对联的产生。中国对联生成任务可以看作是两句诗生成的简化形式。给定诗的第一行，生成器应该相应地生成第二行，这与对联生成的过程类似。但是，对联生成和诗歌生成之间仍然存在一些差异。生成后续从句以匹配给定的前置从句的任务比生成一首诗的所有句子更明确。此外，并不是诗中所有的句子都需要遵循对联的约束。</p>
<p>​		总的来说，国内基于seq2seq的对联自动生成系统在技术上已经取得了一定的进展，但仍面临着诸多挑战，如语义理解、语法结构、韵律要求等。未来，随着深度学习技术的不断发展和对联生成应用场景的不断拓展，这些挑战将逐渐得到解决，对联生成系统的性能和应用前景也将不断提升。</p>
<h2 id="二、相关理论及其技术介绍"><a href="#二、相关理论及其技术介绍" class="headerlink" title="二、相关理论及其技术介绍"></a>二、相关理论及其技术介绍</h2><h3 id="2-1-循环神经网络"><a href="#2-1-循环神经网络" class="headerlink" title="2.1 循环神经网络"></a>2.1 循环神经网络</h3><h4 id="2-1-1-标准循环神经网络"><a href="#2-1-1-标准循环神经网络" class="headerlink" title="2.1.1 标准循环神经网络"></a>2.1.1 标准循环神经网络</h4><p>​		基础的神经网络包括输入层、隐藏层和输出层三层结构，其只在层与层之间建立连接。而标准循环神经网络 RNN(Recurrent Neural Network)在此基础上，在同层之间的神经元之间也建立了连接。RNN 的神经网络结构如图 2.1 所示，等号右边为神经网络按时间展开图，等号左边是其简化图。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/../images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/clip_image002.jpg" alt="img"></p>
<h4 id="2-1-2-长短时记忆网络"><a href="#2-1-2-长短时记忆网络" class="headerlink" title="2.1.2 长短时记忆网络"></a>2.1.2 长短时记忆网络</h4><p>​		长短时记忆网络 LSTM 是循环神经网络的一个最常见的扩展模型，其就是为了解决一般 RNN 网络的缺陷，更有效的应对产期依赖问题。LSTM的隐藏层比RNN更为复杂，采用了三个“门”结构，用来解决长期依赖问题。如图2.2所示LSTM的隐藏层分别包含了输入门、遗忘门和输出门。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/../images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/clip_image002-17337985776821.jpg" alt="img"></p>
<p>​		这是最基本的 LSTM 结构，目前有 LSTM 的变种形式如 GRU 等等，但是基本思想都是统一的。LSTM 和 GRU 是目前比较常见的神经网络隐藏层单元结构，除此以外，还有 Koutnik提出的 Clockwork RNN 结构，Yao 提出的 Depth Gated RNN 结构等[2]，对于具体的任务，可以适当变形以适应任务需要。</p>
<h3 id="2-2-注意力机制"><a href="#2-2-注意力机制" class="headerlink" title="2.2 注意力机制"></a>2.2 注意力机制</h3><p>​		注意力机制（Attention Mechanism，简称 AM）最早的提出是在图像领域，受到人类注意力机制的启发，人类观察图像时往往有重点的将注意力集中在图像的特定部分并且会根据之前观察图像的经验来观察之后的图像。基于注意力机制的文本分类机制为每个词赋予了权重α，并根据权重生成语义编码C。其编码的三个阶段具体计算步骤为：</p>
<ol>
<li>计算 Query和不同 Key 的相关性，计算不同 Value 值的权重系数。</li>
<li>对上一阶段的输出进行归一化处理，将数值的范围映射到 0 和 1 之间。</li>
<li>根据权重系数对Value进行加权求和，从而得到最终的注意力数值。</li>
</ol>
<p>​		在注意力模型中，由于每一次输出的词语在计算的时候，使用到的语义编码C 都是不一样的，这也体现出注意力的意义，在很多任务中都已经取得了很好的效果。</p>
<h3 id="2-3-序列到序列模型"><a href="#2-3-序列到序列模型" class="headerlink" title="2.3 序列到序列模型"></a>2.3 序列到序列模型</h3><h4 id="2-3-1-经典的序列到序列模型"><a href="#2-3-1-经典的序列到序列模型" class="headerlink" title="2.3.1 经典的序列到序列模型"></a>2.3.1 经典的序列到序列模型</h4><p>​		序列到序列模型（seq2seq）亦称为编码-解码模型，由谷歌公司于2014年在论文《Sequence to sequence learning with neural networks》中提出。序列到序列模型的提出在整个深度学习领域获得了很大的影响。近年来在机器翻译、语音识别、图像识别、文本生成等领域的大部分研究都是围绕序列到序列的模型框架展开。如图2.3所展示了一个经典的序列到序列模型。模型包含了一个编码器（Encoder）和一个解码器（Decoder），编码器的作用是提取输入序列特征，并将其压缩成一个固定大小的语义向量C，解码器的作用是解读语义向量C，将其转化为目标输出序列。其中编码器和解码器一般采用循环神经网络[3]。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/../images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/clip_image001.png" alt="img"></p>
<h4 id="2-3-2-基于注意力机制的序列到序列模型"><a href="#2-3-2-基于注意力机制的序列到序列模型" class="headerlink" title="2.3.2 基于注意力机制的序列到序列模型"></a>2.3.2 基于注意力机制的序列到序列模型</h4><p>​		经典的序列到序列模型在很多问题上都非常有效，但是也存在问题。最大的不足在于，编码器和解码器仅通过一个固定的语义向量C进行联系，每个输出时刻语义向量的值都是不变的，且语义向量并不能够将整个序列的信息完全表示，如此解码器在每个时刻仅根据历史的信息和固定的语义向量C进行输出，这样会导致本应该和输出强相关的输入信息被严重的稀释了[4]。</p>
<p>​		因此将注意力机制应用于序列到序列模型，如图2.4展示了基于注意力机制的序列到序列模型示意图。用经典的序列到序列模型结合注意力机制，使得编码器和解码器之间通过一个可变的语义向量进行联系，每个输出时刻语义向量都是不同的，可变的Ci表示了每个时刻输出最相关的输入信息。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/../images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/clip_image001-17337987235392.png" alt="img"></p>
<p>​		本文主要用到基于注意力机制的序列到序列模型，因此这里展开描述基于注意力机制的序列到序列模型计算过程步骤：</p>
<p>​		假设基于注意力机制的序列到序列模型输入的源序列为S &#x3D; (x1,x2,…,xm)，输出的目标序列为T&#x3D; (y1,y2,…,yn)，那么在第i时刻模型的输出计算过程可以表示如下：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/../images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/clip_image001-17337987355173.png" alt="img"></p>
<p>​		其中，Ci不是一个固定的值，会根据每一个时刻的变化而变化，由编码器的隐藏向量(h1,…,hm)通过如下公式计算得到：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/../images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/clip_image001-17337987461764.png" alt="img"></p>
<p>​		其中，𝛼i𝑗为注意力权值，计算公式如下：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/../images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/clip_image001-17337987565385.png" alt="img"></p>
<p>​		其中，</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/../images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/clip_image001-17337987685056.png" alt="img"></p>
<p>​		其中，𝑠i−1表示解码器第i-1时刻的隐藏层状态，函数F(𝑎, 𝑏)表示计算a和b的相似度。首先计算解码器隐藏层状态和编码器隐藏层状态的相似度，然后对计算出的相似度采用类Softmax函数进行归一化，得到注意力权值，最后注意力权值与编码器隐藏状态相乘求和得到语义向量Ct。</p>
<h2 id="三、对联生成模型设计"><a href="#三、对联生成模型设计" class="headerlink" title="三、对联生成模型设计"></a>三、对联生成模型设计</h2><h3 id="3-1-Encoder-Decoder-框架结构简介"><a href="#3-1-Encoder-Decoder-框架结构简介" class="headerlink" title="3.1 Encoder-Decoder 框架结构简介"></a>3.1 Encoder-Decoder 框架结构简介</h3><p>​		对联生成问题为典型的序列生成问题，这里采用最经典的 Encoder-Decoder框架结构，由于预测句子中下一个词一般需要用到前面已经生成的词，前后词语之间并不是独立的，RNN 同层节点之间相互连接能够体现这种前后词语之间的联系，并且同层节点之间的权值是共享的，因此本文任务选择使用 RNN Encoder-Decoder。一般的 RNN 结构需要将输入压缩成一个固定长度的向量，这就很难处理一些比较长的句子，特别是那些比训练集中语句更长的语句，本文在编码阶段采用的是双向RNN结构——BiGRU，这在语音识别方面已经得到了很有效的应用，解码阶段选择的就是GRU 结构。为了在每次生成输出词语的时候充分利用输入序列携带的信息，使输入序列中的不同词语对输出词语有不同的影响，本文在解码阶段使用了注意力机制。另外，为了体现上下联语句在语义和语境上的一致性，本文在解码的时候将含有上联整句信息的句向量考虑进去，下图是本文建立的对联生成模型的总体结构图。</p>
<p> <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/../images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/clip_image002-17337988378657.jpg" alt="img"></p>
<h4 id="3-1-1-输入处理"><a href="#3-1-1-输入处理" class="headerlink" title="3.1.1 输入处理"></a>3.1.1 输入处理</h4><p>​		本文任务的基本模式就是，输入上联输出对应的下联，这里的输入上联是汉字组成的序列。很显然，将这个任务转化为深度学习问题，必须将上联的文字符号化输入计算机中。第一步任务就是将序列中汉字转化为一个向量，就是所谓的词向量。一般的词向量在训练时只考虑到词语与其所在训练序列中的前后词语之间的关系，由于对联任务的特殊性，不仅需要考虑前后词语之间的关系，还需要考虑上下联中对应位置的词语之间的联系，于是，在训练词向量的时候将上下联对应位置的字考虑在内，也就是将其加入上下文中，将训练出来的这种词向量称之为对联字向量。</p>
<h4 id="3-1-2-编码阶段"><a href="#3-1-2-编码阶段" class="headerlink" title="3.1.2 编码阶段"></a>3.1.2 编码阶段</h4><p>​		为了体现序列前后词语之间的联系，在编码阶段本文使用的是BiGRU 的结构。门控循环单元神经网络（gated recurrent unit neural network，简称 GRU）是由 Cho 等人在 2014 年提出来的，是 RNN 的衍生物，属于 RNN 的一种变种，与 RNN 的结构本质上并没有什么不同，差异在于计算隐藏层状态的函数。</p>
<p>​		GRU 使用了更新门（update gate）与重置门（reset gate）来控制标准 RNN 的梯度消失的问题，这两个门控向量基本上决定了 GRU 最终输出哪些信息。这两门控机制能够保存长期序列中的信息，且不会随着时间变长而被清除或因与预测不相关而被移除。</p>
<p>​		本文中编码阶段使用的是双向的GRU，由图4.1可以看出，一个前向的GRU，一个反向的 GRU，正向的和反向的 GRU 实际上并没有什么区别，只是输入序列的顺序不同。</p>
<h4 id="3-1-3-解码阶段"><a href="#3-1-3-解码阶段" class="headerlink" title="3.1.3 解码阶段"></a>3.1.3 解码阶段</h4><p>​		解码阶段的任务是根据输入 X 的中间语义表示 C 以及前面生成的历史信息（y1,y2,…,yi-1）来生成 i 时刻要输出的词语 yi，前面说过，解码阶段使用的依然是RNN 的变体 GRU。在基础的 Decoder 中，每个 ci 都一模一样的，并不能加强或者减轻某个字对某个词的作用大小，很明显上联中对应位置的字对当前字生成的影响较大，其他位置的字对当前字生成的影响较小。为了解决这个问题，体现出上联中不同字对于下联中不同词语的影响，在解码过程中应用了 Attention 机制[5]。AM 模型可以说是今年来 NLP 领域中的重要进展之一，其效果在很多场景得到证实。在 Decoder中加入 AM 后，在生成每一个 yi 的时候的中间语义向量 ci 都是不相同的，是根据当前生成字而不断变化的[6]。</p>
<h3 id="3-2-数据处理部分"><a href="#3-2-数据处理部分" class="headerlink" title="3.2 数据处理部分"></a>3.2 数据处理部分</h3><h4 id="3-2-1-噪声数据摘除"><a href="#3-2-1-噪声数据摘除" class="headerlink" title="3.2.1 噪声数据摘除"></a>3.2.1 噪声数据摘除</h4><p>​		数据集来源：<a target="_blank" rel="noopener" href="https://github.com/wb14123/couplet-dataset">https://github.com/wb14123/couplet-dataset</a> 此数据集包含了五个文件，将文件按照（test+train）的顺序进行合并[7]。之后发现有14条数据有问题，其中前10个问题为上联，后4个问题为下联。经过对噪声数据进行处理后，最终获得744915条对联数据。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/../images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/clip_image002.png" alt="img"></p>
<h4 id="3-2-2-添加输入开始与结束标志"><a href="#3-2-2-添加输入开始与结束标志" class="headerlink" title="3.2.2 添加输入开始与结束标志"></a>3.2.2 添加输入开始与结束标志</h4><p>&lt; start&gt; 表示一个输入的开始 </p>
<p>&lt; end&gt; 表示一个输入的结束</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/../images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/clip_image002-17337989826658.png" alt="img"></p>
<h4 id="3-2-3-建立词库与字典"><a href="#3-2-3-建立词库与字典" class="headerlink" title="3.2.3 建立词库与字典"></a>3.2.3 建立词库与字典</h4><p>​		在字典的创建过程中，主要先用一个辅助字典，存储每个词汇出现的频率，然后根据频率排序辅助字典。然后初始化两个字典，遍历辅助字典,可用当前字典（非辅助字典）的长度作为词汇数字标识。 在该过程中，我们还可以根据频率筛选出频率大于一定阈值的词汇，即抛弃低频词汇[8]。</p>
<p>​		词库：由上下联所有字符，可用列表表示</p>
<p>​		字典：建立词汇–&gt;向量，向量–&gt;词汇两个字典。向量在这里可以理解为数字化，最终的目的是向量化。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/../images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/clip_image002-17337990023979.png" alt="img"></p>
<h4 id="3-2-4-数据向量化"><a href="#3-2-4-数据向量化" class="headerlink" title="3.2.4 数据向量化"></a>3.2.4 数据向量化</h4><p>​		根据前一步中创建的“词汇–&gt;向量”字典将所有数据向量化。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/../images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/clip_image002-173379901873010.jpg" alt="img"></p>
<h4 id="3-2-5-数据集划分及封装"><a href="#3-2-5-数据集划分及封装" class="headerlink" title="3.2.5 数据集划分及封装"></a>3.2.5 数据集划分及封装</h4><p>​		我们总的数据为744915条，按照8:1:1的方式划分训练集，验证集，测试集。数据集的封装主要使用paddlepaddle以及paddlenlp提供的方法,其中paddlenlp主要是进行每个minibath数据的padding操作，统一长度[9]。</p>
<p>​		最终我们得到封装好的训练集、验证集，测试集。以训练集为例，每个元素包括五部分：</p>
<ol>
<li>上联输入向量</li>
<li>输入向量未填充前的长度，用于控制LSTM的隐藏状态是否更新填充位置</li>
<li>下联输入向量，不包含最后一个位置的元素</li>
<li>下联输入向量，不包含第一个元素，然后在最后一个扩维，用于loss计算</li>
<li>下联输入向量的mask向量</li>
</ol>
<h2 id="四、模型训练"><a href="#四、模型训练" class="headerlink" title="四、模型训练"></a>四、模型训练</h2><h3 id="4-1-参数设定"><a href="#4-1-参数设定" class="headerlink" title="4.1 参数设定"></a>4.1 参数设定</h3><ul>
<li>num_layers&#x3D;2:LSTM的层数</li>
<li>hidden_size&#x3D;128:隐藏层的状态数</li>
<li>embedding_dim&#x3D;256:嵌入层的维度</li>
<li>lr&#x3D;0.001:学习率</li>
<li>log_freq&#x3D;200:每200个batch输入一次日志信息</li>
<li>max_grad_norm&#x3D;5:梯度裁剪</li>
<li>optimizer&#x3D;Adam():优化器，不是参数，在这里我们把他看作一个参数</li>
<li>loss&#x3D;CrossEntropy():损失函数，使用的是带掩码的交叉熵损失函数</li>
<li>metrics&#x3D;Preplexity():评价准则，困惑度</li>
</ul>
<h3 id="4-2-模型训练"><a href="#4-2-模型训练" class="headerlink" title="4.2 模型训练"></a>4.2 模型训练</h3><p>部分关键代码：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/../images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/clip_image002-173379911835411.jpg" alt="img"></p>
<p>使用model.fit()函数进行训练及验证。</p>
<p>部分参数设置：</p>
<ul>
<li>epcohs&#x3D;20</li>
<li>eos_id&#x3D;word2id_dict[‘<end>‘]</end></li>
<li>num_layers&#x3D;2</li>
<li>dropout_rate&#x3D;0.2</li>
<li>hidden_size&#x3D;128</li>
<li>embedding_dim&#x3D;256</li>
<li>max_grad_norm&#x3D;5</li>
<li>lr&#x3D;0.001</li>
<li>log_freq&#x3D;200</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/../images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/clip_image002-173379914079712.png" alt="img"></p>
<h3 id="4-3-模型预测"><a href="#4-3-模型预测" class="headerlink" title="4.3 模型预测"></a>4.3 模型预测</h3><p>​		模型的预测使用了beam search(束搜索)。常规的搜索方法有greedy search（贪心搜索）和exhaustive search（穷举搜索）。</p>
<p>​		穷举搜索：穷举所有可能的输出结果。例如输出序列长度为3，候选项为4，那么就有4<em>4</em>4&#x3D;64种可能，当输出序列长度为10时，就会有4**10种可能，这种幂级增长对于计算机性能的要求是极高的，耗时耗力。</p>
<p>​		贪心搜索：每次选择概率最大的候选者作为输出。搜索空间小，以局部最优解期望全局最优解，无法保证最终结果是做优的，但是效率高。</p>
<p>​		束搜索：束搜索可以看作是穷举搜索和贪心搜索的折中方案。需要设定一个beam size(束宽)，当设为1时即为贪心搜索，当设为候选项的数量时即为穷举搜索。</p>
<h3 id="4-4-展示界面搭建"><a href="#4-4-展示界面搭建" class="headerlink" title="4.4 展示界面搭建"></a>4.4 展示界面搭建</h3><p>​		展示界面使用Python自带的TKinter包进行搭建，主要包括两个文本框和两个动作按钮。用户输入对联的上联，然后点击相应按钮，系统会提取用户的输入，将其向量化，然后送入训练好的模型中，产生输出，然后显示在另一个文本框中。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/../images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/clip_image002-173379917879313.jpg" alt="img"></p>
<h2 id="五、模型评测"><a href="#五、模型评测" class="headerlink" title="五、模型评测"></a>五、模型评测</h2><h3 id="5-1-loss曲线"><a href="#5-1-loss曲线" class="headerlink" title="5.1 loss曲线"></a>5.1 loss曲线</h3><p>​		loss曲线数据由PaddlePaddle提供的接口在训练时保存在log文件中，之后通过可视化工具进行展示。横轴表示训练的minibatch，纵轴表示loss值。</p>
<p>​		通过训练集与验证集的lossqu曲线可以看出，训练在前期收敛较快，训练集后期有波动，但是验证集后期仍为缓慢下降趋势，说明模型的训练效果是不错的。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/../images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/clip_image002-173379922392814.png" alt="img"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/../images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/clip_image002-173379922806515.png" alt="img"></p>
<h3 id="5-2-困惑度"><a href="#5-2-困惑度" class="headerlink" title="5.2 困惑度"></a>5.2 困惑度</h3><p>​		困惑度数据的获取方式同loss。通过训练集与验证集的困惑度曲线，任务模型训练效果可以。但是训练集的困惑度后期呈现为直线，这应该是存在问题的，有待分析解决。我们在测试集上进行了困惑度分析，每个batch的数据困惑度基本一致，说明模型波动较小，效果理想。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/../images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/clip_image002-173379924722916.png" alt="img"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/../images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/clip_image002-173379925096617.png" alt="img"></p>
<h2 id="六、结语"><a href="#六、结语" class="headerlink" title="六、结语"></a>六、结语</h2><p>​		对联是中华文化一种独特的艺术形式，其上下联之间讲究对仗工整、平仄协调，这要求对联创作者具备丰富的知识储备和深厚的文学素养，因此创作对联对普通人来说稍显困难。对于计算机来说，在自然语言处理领域，对联的生成也是一项比较困难的任务。近年来，深度学习技术快速发展，在如图像识别、语音识别等机器学习领域表现出色，自然语言处理作为机器学习的重要分支，深度学习技术也推动着自然语言处理技术不断发展。</p>
<p>​		本文首先讨论了自动生成对联的研究背景和研究意义，以及对联生成模型的国内外研究现状。介绍了循环神经网络和注意力机制，并且采用基于注意力机制的序列到序列模型对对联生成系统进行进一步研究。掌握了基于编码-解码框架的神经网络模型、注意力机制模型等算法，明确研究方向，舍弃了传统的基于循环神经网络或卷积神经网络的方法，完全使用注意力机制的神经网络结构进行对联的自动生成。结果表明注意力机制在对联的自动生成任务上具有不可替代的作用。</p>
<h2 id="七、参考文献"><a href="#七、参考文献" class="headerlink" title="七、参考文献"></a>七、参考文献</h2><p>[1]   Manurung, R., Ritchie, G. and Thompson, H. (2012) Using genetic algorithms to create meaningful poetic text. J. Exp. Theor. Artif. Intel., 24, 43–64.</p>
<p>[2]   Sundermeyer, M., Schlüter, R. and Ney, H. (2012) LSTM Neural Networks for Language Modeling. In Proceedings of Interspeech 2012, Portland, OR, 9–13 September, pp. 601–608. Association for Computational Linguistics, Stroudsburg.</p>
<p>[3]   Papineni, K., Roukos, S., Ward, T. and Zhu, W.J. (2002) BLEU: a Method for Automatic Evaluation of Machine Translation. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, Philadelphia, Pennsylvania, USA, 19–24 July 2002, pp. 311–318. Association for Computational Linguistics, Stroudsburg.</p>
<p>[4]   王治权.基于注意力机制和改进型 RNN 的 Web 文本情感分析研究[D]. 2018.</p>
<p>[5]   王哲.基于深度学习技术的中国传统诗歌生成方法研究[D].中国科学技术大学,2017.</p>
<p>[6]   Koutnik J, Greff K, Gomez F, et al. A clockwork rnn[J]. arXiv preprint arXiv:1402.3511, 2014.</p>
<p>[7]   蒋锐滢,崔磊,何晶,等.基于主题模型和统计机器翻译方法的中文格律诗自动生成 [J].计算机学报, 2015.</p>
<p>[8]   Oliveira, H.G., Hervas, R., Diaz, A. and Gervas, P. (2017)Multilingual extension and evaluation of a poetry generator. Nat.Lang. Eng., 23, 929–967.</p>
<p>[9]   Zhang J, Du J, Dai L. A GRU-based Encoder-Decoder Approach with Attention for Online Handwritten Mathematical Expression Recognition[J]. 2017.</p>
</article><div class="post-copyright"><div class="copyright-cc-box"><i class="anzhiyufont anzhiyu-icon-copyright"></i></div><div class="post-copyright__author_box"><a class="post-copyright__author_img" href="/" title="头像"><img class="post-copyright__author_img_back" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/touxiang.jpg" title="头像" alt="头像"><img class="post-copyright__author_img_front" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/touxiang.jpg" title="头像" alt="头像"></a><div class="post-copyright__author_name">附加</div><div class="post-copyright__author_desc">允许一切发生</div></div><div class="post-copyright__post__info"><a class="post-copyright__original" title="该文章为原创文章，注意版权协议" href="http://example.com/2024/06/09/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/">原创</a><a class="post-copyright-title"><span onclick="rm.copyPageUrl('http://example.com/2024/06/09/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/')">基于循环神经网络的对联自动生成研究</span></a></div><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"><div class="post-reward" onclick="anzhiyu.addRewardMask()"><div class="reward-button button--animated" title="赞赏作者"><i class="anzhiyufont anzhiyu-icon-hand-heart-fill"></i>打赏作者</div><div class="reward-main"><div class="reward-all"><span class="reward-title">感谢你赐予我前进的力量</span><ul class="reward-group"><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul><a class="reward-main-btn" href="/about/#about-reward" target="_blank"><div class="reward-text">赞赏者名单</div><div class="reward-dec">因为你们的支持让我意识到写文章的价值🙏</div></a></div></div></div><div id="quit-box" onclick="anzhiyu.removeRewardMask()" style="display: none"></div></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="使用手机访问这篇文章"><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="http://example.com/2024/06/09/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/"></div><div class="reward-dec">使用手机访问这篇文章</div></div></div></div></div><div class="share-link weibo"><a class="share-button" target="_blank" href="https://service.weibo.com/share/share.php?title=基于循环神经网络的对联自动生成研究&amp;url=http://example.com/2024/06/09/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/&amp;pic=/images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/cover.jpg" rel="external nofollow noreferrer noopener"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a></div><script>function copyCurrentPageUrl() {
  var currentPageUrl = window.location.href;
  var input = document.createElement("input");
  input.setAttribute("value", currentPageUrl);
  document.body.appendChild(input);
  input.select();
  input.setSelectionRange(0, 99999);
  document.execCommand("copy");
  document.body.removeChild(input);
}</script><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="复制链接" onclick="copyCurrentPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div></div><div class="post-copyright__notice"><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">附加</a>！</span></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__tag-list"><a class="post-meta__box__tags" href="/tags/%E4%BD%9C%E4%B8%9A/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>作业<span class="tagsPageCount">8</span></a><a class="post-meta__box__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>深度学习<span class="tagsPageCount">2</span></a><a class="post-meta__box__tags" href="/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>循环神经网络<span class="tagsPageCount">1</span></a></div></div></div><div class="post_share"><div class="social-share" data-image="/images/postsImg/Nginx/cover.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"/><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer="defer"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/05/23/%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%9E%E9%AA%8C/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/images/postsImg/%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%9E%E9%AA%8C/cover.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">决策树实验</div></div></a></div><div class="next-post pull-right"><a href="/2024/06/15/%E6%96%91%E9%A9%AC%E9%97%AE%E9%A2%98%E5%AE%9E%E9%AA%8C/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/images/postsImg/%E6%96%91%E9%A9%AC%E9%97%AE%E9%A2%98%E5%AE%9E%E9%AA%8C/cover.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">斑马问题实验</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="anzhiyufont anzhiyu-icon-thumbs-up fa-fw" style="font-size: 1.5rem; margin-right: 4px"></i><span>喜欢这篇文章的人也看了</span></div><div class="relatedPosts-list"><div><a href="/2024/05/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%8A%A5%E5%91%8A/" title="深度学习论文阅读报告"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/images/postsImg/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%8A%A5%E5%91%8A/cover.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-05-08</div><div class="title">深度学习论文阅读报告</div></div></a></div><div><a href="/2024/05/23/%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%9E%E9%AA%8C/" title="决策树实验"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/images/postsImg/%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%9E%E9%AA%8C/cover.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-05-23</div><div class="title">决策树实验</div></div></a></div><div><a href="/2024/06/28/%E5%86%B3%E7%AD%96%E6%A0%91%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6/" title="决策树分类算法研究"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/images/postsImg/%E5%86%B3%E7%AD%96%E6%A0%91%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6/cover.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-06-28</div><div class="title">决策树分类算法研究</div></div></a></div><div><a href="/2024/04/22/%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95%E5%AE%9E%E9%AA%8C/" title="搜索算法实验"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/images/postsImg/%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95%E5%AE%9E%E9%AA%8C/cover.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-04-22</div><div class="title">搜索算法实验</div></div></a></div><div><a href="/2024/05/06/%E7%A9%B7%E4%B8%BE%E6%90%9C%E7%B4%A2%E5%AE%9E%E9%AA%8C/" title="穷举搜索实验"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/images/postsImg/%E7%A9%B7%E4%B8%BE%E6%90%9C%E7%B4%A2%E5%AE%9E%E9%AA%8C/cover.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-05-06</div><div class="title">穷举搜索实验</div></div></a></div><div><a href="/2024/03/12/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%AE%9E%E9%AA%8C/" title="线性回归实验"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/images/postsImg/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%AE%9E%E9%AA%8C/cover.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-03-12</div><div class="title">线性回归实验</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="anzhiyufont anzhiyu-icon-comments"></i><span> 评论</span></div><div class="comment-randomInfo"><a onclick="anzhiyu.addRandomCommentInfo()" href="javascript:void(0)">匿名评论</a><a href="/privacy" style="margin-left: 4px">隐私政策</a></div><div class="comment-tips" id="comment-tips"><span>✅ 你无需删除空行，直接评论以获取最佳展示效果</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div><div class="comment-barrage"></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-content"><div class="author-info__sayhi" id="author-info__sayhi" onclick="anzhiyu.changeSayHelloText()"></div><div class="author-info-avatar"><img class="avatar-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-status"><img class="g-status" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/images/furong.jpg" alt="status"/></div></div><div class="author-info__description"><div style="line-height:1.38;margin:0.6rem 0;text-align:justify;color:rgba(255, 255, 255, 0.8);">这有关于<b style="color:#fff">产品、设计、开发</b>相关的问题和看法，还有<b style="color:#fff">文章翻译</b>和<b style="color:#fff">分享</b>。</div><div style="line-height:1.38;margin:0.6rem 0;text-align:justify;color:rgba(255, 255, 255, 0.8);">相信你可以在这里找到对你有用的<b style="color:#fff">知识</b>和<b style="color:#fff">教程</b>。</div></div><div class="author-info__bottom-group"><a class="author-info__bottom-group-left" href="/"><h1 class="author-info__name">附加</h1><div class="author-info__desc">允许一切发生</div></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://github.com/fujia-233" target="_blank" title="Github"><i class="anzhiyufont anzhiyu-icon-github"></i></a><a class="social-icon faa-parent animated-hover" href="https://space.bilibili.com/32491339" target="_blank" title="BiliBili"><i class="anzhiyufont anzhiyu-icon-bilibili"></i></a></div></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>文章目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6"><span class="toc-number">1.</span> <span class="toc-text">基于循环神经网络的对联自动生成研究</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%A6%82%E8%BF%B0"><span class="toc-number">1.1.</span> <span class="toc-text">一、概述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E9%80%89%E9%A2%98%E8%83%8C%E6%99%AF%E5%8F%8A%E6%84%8F%E4%B9%89"><span class="toc-number">1.1.1.</span> <span class="toc-text">1.1 选题背景及意义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E5%BC%80%E5%8F%91%E5%9B%A2%E9%98%9F"><span class="toc-number">1.1.2.</span> <span class="toc-text">1.2 开发团队</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83"><span class="toc-number">1.1.3.</span> <span class="toc-text">1.3 开发环境</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-%E5%9B%BD%E5%86%85%E5%A4%96%E7%A0%94%E7%A9%B6%E7%8E%B0%E7%8A%B6"><span class="toc-number">1.1.4.</span> <span class="toc-text">1.4 国内外研究现状</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E7%9B%B8%E5%85%B3%E7%90%86%E8%AE%BA%E5%8F%8A%E5%85%B6%E6%8A%80%E6%9C%AF%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.2.</span> <span class="toc-text">二、相关理论及其技术介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">1.2.1.</span> <span class="toc-text">2.1 循环神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-1-%E6%A0%87%E5%87%86%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">1.2.1.1.</span> <span class="toc-text">2.1.1 标准循环神经网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-2-%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C"><span class="toc-number">1.2.1.2.</span> <span class="toc-text">2.1.2 长短时记忆网络</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6"><span class="toc-number">1.2.2.</span> <span class="toc-text">2.2 注意力机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E5%BA%8F%E5%88%97%E5%88%B0%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.2.3.</span> <span class="toc-text">2.3 序列到序列模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-1-%E7%BB%8F%E5%85%B8%E7%9A%84%E5%BA%8F%E5%88%97%E5%88%B0%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.2.3.1.</span> <span class="toc-text">2.3.1 经典的序列到序列模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-2-%E5%9F%BA%E4%BA%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E5%BA%8F%E5%88%97%E5%88%B0%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.2.3.2.</span> <span class="toc-text">2.3.2 基于注意力机制的序列到序列模型</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%AF%B9%E8%81%94%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1"><span class="toc-number">1.3.</span> <span class="toc-text">三、对联生成模型设计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-Encoder-Decoder-%E6%A1%86%E6%9E%B6%E7%BB%93%E6%9E%84%E7%AE%80%E4%BB%8B"><span class="toc-number">1.3.1.</span> <span class="toc-text">3.1 Encoder-Decoder 框架结构简介</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-1-%E8%BE%93%E5%85%A5%E5%A4%84%E7%90%86"><span class="toc-number">1.3.1.1.</span> <span class="toc-text">3.1.1 输入处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-2-%E7%BC%96%E7%A0%81%E9%98%B6%E6%AE%B5"><span class="toc-number">1.3.1.2.</span> <span class="toc-text">3.1.2 编码阶段</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-3-%E8%A7%A3%E7%A0%81%E9%98%B6%E6%AE%B5"><span class="toc-number">1.3.1.3.</span> <span class="toc-text">3.1.3 解码阶段</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E9%83%A8%E5%88%86"><span class="toc-number">1.3.2.</span> <span class="toc-text">3.2 数据处理部分</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-1-%E5%99%AA%E5%A3%B0%E6%95%B0%E6%8D%AE%E6%91%98%E9%99%A4"><span class="toc-number">1.3.2.1.</span> <span class="toc-text">3.2.1 噪声数据摘除</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-2-%E6%B7%BB%E5%8A%A0%E8%BE%93%E5%85%A5%E5%BC%80%E5%A7%8B%E4%B8%8E%E7%BB%93%E6%9D%9F%E6%A0%87%E5%BF%97"><span class="toc-number">1.3.2.2.</span> <span class="toc-text">3.2.2 添加输入开始与结束标志</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-3-%E5%BB%BA%E7%AB%8B%E8%AF%8D%E5%BA%93%E4%B8%8E%E5%AD%97%E5%85%B8"><span class="toc-number">1.3.2.3.</span> <span class="toc-text">3.2.3 建立词库与字典</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-4-%E6%95%B0%E6%8D%AE%E5%90%91%E9%87%8F%E5%8C%96"><span class="toc-number">1.3.2.4.</span> <span class="toc-text">3.2.4 数据向量化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-5-%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%92%E5%88%86%E5%8F%8A%E5%B0%81%E8%A3%85"><span class="toc-number">1.3.2.5.</span> <span class="toc-text">3.2.5 数据集划分及封装</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">1.4.</span> <span class="toc-text">四、模型训练</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E5%8F%82%E6%95%B0%E8%AE%BE%E5%AE%9A"><span class="toc-number">1.4.1.</span> <span class="toc-text">4.1 参数设定</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">1.4.2.</span> <span class="toc-text">4.2 模型训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B"><span class="toc-number">1.4.3.</span> <span class="toc-text">4.3 模型预测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-%E5%B1%95%E7%A4%BA%E7%95%8C%E9%9D%A2%E6%90%AD%E5%BB%BA"><span class="toc-number">1.4.4.</span> <span class="toc-text">4.4 展示界面搭建</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B"><span class="toc-number">1.5.</span> <span class="toc-text">五、模型评测</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-loss%E6%9B%B2%E7%BA%BF"><span class="toc-number">1.5.1.</span> <span class="toc-text">5.1 loss曲线</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E5%9B%B0%E6%83%91%E5%BA%A6"><span class="toc-number">1.5.2.</span> <span class="toc-text">5.2 困惑度</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E7%BB%93%E8%AF%AD"><span class="toc-number">1.6.</span> <span class="toc-text">六、结语</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83%E3%80%81%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-number">1.7.</span> <span class="toc-text">七、参考文献</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-history"></i><span>最近发布</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/12/04/Nginx/" title="Nginx"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/images/postsImg/Nginx/cover.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Nginx"/></a><div class="content"><a class="title" href="/2024/12/04/Nginx/" title="Nginx">Nginx</a><time datetime="2024-12-03T16:00:00.000Z" title="发表于 2024-12-04 00:00:00">2024-12-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/06/28/%E5%86%B3%E7%AD%96%E6%A0%91%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6/" title="决策树分类算法研究"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/images/postsImg/%E5%86%B3%E7%AD%96%E6%A0%91%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6/cover.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="决策树分类算法研究"/></a><div class="content"><a class="title" href="/2024/06/28/%E5%86%B3%E7%AD%96%E6%A0%91%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6/" title="决策树分类算法研究">决策树分类算法研究</a><time datetime="2024-06-27T16:00:00.000Z" title="发表于 2024-06-28 00:00:00">2024-06-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/06/15/%E6%96%91%E9%A9%AC%E9%97%AE%E9%A2%98%E5%AE%9E%E9%AA%8C/" title="斑马问题实验"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/images/postsImg/%E6%96%91%E9%A9%AC%E9%97%AE%E9%A2%98%E5%AE%9E%E9%AA%8C/cover.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="斑马问题实验"/></a><div class="content"><a class="title" href="/2024/06/15/%E6%96%91%E9%A9%AC%E9%97%AE%E9%A2%98%E5%AE%9E%E9%AA%8C/" title="斑马问题实验">斑马问题实验</a><time datetime="2024-06-14T16:00:00.000Z" title="发表于 2024-06-15 00:00:00">2024-06-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/06/09/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/" title="基于循环神经网络的对联自动生成研究"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/images/postsImg/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/cover.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于循环神经网络的对联自动生成研究"/></a><div class="content"><a class="title" href="/2024/06/09/%E5%9F%BA%E4%BA%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AF%B9%E8%81%94%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%A0%94%E7%A9%B6/" title="基于循环神经网络的对联自动生成研究">基于循环神经网络的对联自动生成研究</a><time datetime="2024-06-08T16:00:00.000Z" title="发表于 2024-06-09 00:00:00">2024-06-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/05/23/%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%9E%E9%AA%8C/" title="决策树实验"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/images/postsImg/%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%9E%E9%AA%8C/cover.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="决策树实验"/></a><div class="content"><a class="title" href="/2024/05/23/%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%9E%E9%AA%8C/" title="决策树实验">决策树实验</a><time datetime="2024-05-22T16:00:00.000Z" title="发表于 2024-05-23 00:00:00">2024-05-23</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div id="footer_deal"><a class="deal_link" target="_blank" rel="noopener" href="https://github.com/fujia-233" title="Github"><i class="anzhiyufont anzhiyu-icon-github"></i></a><a class="deal_link" target="_blank" rel="noopener" href="https://space.bilibili.com/32491339" title="Bilibili"><i class="anzhiyufont anzhiyu-icon-bilibili"></i></a><a class="deal_link" target="_blank" rel="noopener" href="https://v.douyin.com/iDGF6jyD" title="抖音"><i class="anzhiyufont anzhiyu-icon-tiktok"></i></a><img class="footer_mini_logo" title="返回顶部" alt="返回顶部" onclick="anzhiyu.scrollToDest(0, 500)" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/touxiang.jpg" size="50px"/><a class="deal_link" href="mailto:2504397114@qq.com" title="email"><i class="anzhiyufont anzhiyu-icon-envelope"></i></a><a class="deal_link" target="_blank" rel="noopener" href="https://weibo.com" title="微博"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a><a class="deal_link" target="_blank" rel="noopener" href="https://www.facebook.com" title="facebook"><i class="anzhiyufont anzhiyu-icon-facebook1"></i></a></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v5.4.0" title="博客框架为Hexo_v5.4.0"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@2.1.5/img/badge/Frame-Hexo.svg" alt="博客框架为Hexo_v5.4.0"/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" data-title="本站项目由Github托管" title="本站项目由Github托管"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@2.1.5/img/badge/Source-Github.svg" alt="本站项目由Github托管"/></a></p></div><div id="footer-bar"><div class="footer-bar-links"><div class="footer-bar-left"><div id="footer-bar-tips"><div class="copyright">&copy;2023 - 2024 By <a class="footer-bar-link" href="/" title="附加" target="_blank">附加</a></div></div><div id="footer-type-tips"></div></div><div class="footer-bar-right"><a class="footer-bar-link" target="_blank" rel="noopener" href="https://github.com/anzhiyu-c/hexo-theme-anzhiyu" title="主题">主题</a><a class="footer-bar-link" target="_blank" rel="noopener" href="https://image.anheyu.com" title="图床">图床</a><a class="footer-bar-link" target="_blank" rel="noopener" href="https://beian.miit.gov.cn/"></a></div></div></div></footer></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">文章</div><div class="length-num">10</div></a><a href="/tags/" title="tag"><div class="headline">标签</div><div class="length-num">11</div></a><a href="/categories/" title="category"><div class="headline">分类</div><div class="length-num">3</div></a></div><span class="sidebar-menu-item-title">功能</span><div class="sidebar-menu-item"><a class="darkmode_switchbutton menu-child" href="javascript:void(0);" title="显示模式"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span>显示模式</span></a></div><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://fujia-233.github.io" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/images/touxiang.jpg" alt="博客"/><span class="back-menu-item-text">博客</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">我的</div><div class="back-menu-list"><a class="back-menu-item" href="/album/" title="相册集"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/images/1.jpg" alt="相册集"/><span class="back-menu-item-text">相册集</span></a><a class="back-menu-item" href="/bangumis/" title="追番页"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/images/2.jpg" alt="追番页"/><span class="back-menu-item-text">追番页</span></a><a class="back-menu-item" href="/music/?id=893451151&amp;server=netease" title="音乐馆"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/images/3.jpg" alt="音乐馆"/><span class="back-menu-item-text">音乐馆</span></a></div></div></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 归档</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/essay/"><span> 随记</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/comments/"><span> 留言板</span></a></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/about/"><span> 关于我</span></a></div></div><span class="sidebar-menu-item-title">标签</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/Java/" style="font-size: 0.88rem;">Java<sup>2</sup></a><a href="/tags/Nginx/" style="font-size: 0.88rem;">Nginx<sup>1</sup></a><a href="/tags/Typora/" style="font-size: 0.88rem;">Typora<sup>1</sup></a><a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" style="font-size: 0.88rem;">人工智能<sup>6</sup></a><a href="/tags/%E4%BD%9C%E4%B8%9A/" style="font-size: 0.88rem;">作业<sup>8</sup></a><a href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/" style="font-size: 0.88rem;">决策树<sup>1</sup></a><a href="/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 0.88rem;">循环神经网络<sup>1</sup></a><a href="/tags/%E6%8A%80%E6%9C%AF/" style="font-size: 0.88rem;">技术<sup>2</sup></a><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 0.88rem;">深度学习<sup>2</sup></a><a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 0.88rem;">算法<sup>1</sup></a><a href="/tags/%E8%AE%BA%E6%96%87/" style="font-size: 0.88rem;">论文<sup>1</sup></a></div></div><hr/></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="anzhiyufont anzhiyu-icon-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="nav-music"><a id="nav-music-hoverTips" onclick="anzhiyu.musicToggle()" accesskey="m">播放音乐</a><div id="console-music-bg"></div><meting-js id="8152976493" server="netease" type="playlist" mutex="true" preload="none" theme="var(--anzhiyu-main)" data-lrctype="0" order="random" volume="0.7"></meting-js></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制选中文本</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>粘贴文本</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>引用到评论</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>复制链接地址</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>复制此图片</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>下载此图片</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开图片</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>站内搜索</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>百度搜索</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>播放音乐</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>切换到上一首</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>切换到下一首</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://y.qq.com/n/ryqq/playlist/8802438608&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>查看所有歌曲</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制歌名</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>随便逛逛</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>博客分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制地址</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">关闭热评</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">深色模式</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>轉為繁體</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.umd.js"></script><script src="https://cdn.cbd.int/instant.page@5.2.0/instantpage.js" type="module"></script><script src="https://cdn.cbd.int/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script src="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.js"></script><canvas id="universe"></canvas><script async src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script>// 消除控制台打印
var HoldLog = console.log;
console.log = function () {};
let now1 = new Date();
queueMicrotask(() => {
  const Log = function () {
    HoldLog.apply(console, arguments);
  }; //在恢复前输出日志
  const grt = new Date("01/01/2023 00:00:00"); //此处修改你的建站时间或者网站上线时间
  now1.setTime(now1.getTime() + 250);
  const days = (now1 - grt) / 1000 / 60 / 60 / 24;
  const dnum = Math.floor(days);
  const ascll = [
    `欢迎使用安知鱼!`,
    `生活明朗, 万物可爱`,
    `
        
       █████╗ ███╗   ██╗███████╗██╗  ██╗██╗██╗   ██╗██╗   ██╗
      ██╔══██╗████╗  ██║╚══███╔╝██║  ██║██║╚██╗ ██╔╝██║   ██║
      ███████║██╔██╗ ██║  ███╔╝ ███████║██║ ╚████╔╝ ██║   ██║
      ██╔══██║██║╚██╗██║ ███╔╝  ██╔══██║██║  ╚██╔╝  ██║   ██║
      ██║  ██║██║ ╚████║███████╗██║  ██║██║   ██║   ╚██████╔╝
      ╚═╝  ╚═╝╚═╝  ╚═══╝╚══════╝╚═╝  ╚═╝╚═╝   ╚═╝    ╚═════╝
        
        `,
    "已上线",
    dnum,
    "天",
    "©2023 By 安知鱼 V1.6.14",
  ];
  const ascll2 = [`NCC2-036`, `调用前置摄像头拍照成功，识别为【小笨蛋】.`, `Photo captured: `, `🤪`];

  setTimeout(
    Log.bind(
      console,
      `\n%c${ascll[0]} %c ${ascll[1]} %c ${ascll[2]} %c${ascll[3]}%c ${ascll[4]}%c ${ascll[5]}\n\n%c ${ascll[6]}\n`,
      "color:#425AEF",
      "",
      "color:#425AEF",
      "color:#425AEF",
      "",
      "color:#425AEF",
      ""
    )
  );
  setTimeout(
    Log.bind(
      console,
      `%c ${ascll2[0]} %c ${ascll2[1]} %c \n${ascll2[2]} %c\n${ascll2[3]}\n`,
      "color:white; background-color:#4fd953",
      "",
      "",
      'background:url("https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/tinggge.gif") no-repeat;font-size:450%'
    )
  );

  setTimeout(Log.bind(console, "%c WELCOME %c 你好，小笨蛋.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(
      console,
      "%c ⚡ Powered by 安知鱼 %c 你正在访问 附加 的博客.",
      "color:white; background-color:#f0ad4e",
      ""
    )
  );

  setTimeout(Log.bind(console, "%c W23-12 %c 你已打开控制台.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(console, "%c S013-782 %c 你现在正处于监控中.", "color:white; background-color:#d9534f", "")
  );
});</script><script async src="/anzhiyu/random.js"></script><div class="js-pjax"><script>(() => {
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://lucent-phoenix-95de8f.netlify.app/.netlify/functions/twikoo',
      region: '',
      onCommentLoaded: () => {
        anzhiyu.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') setTimeout(runFn,0)
    else getScript('https://cdn.cbd.int/twikoo@1.6.39/dist/twikoo.all.min.js').then(runFn)
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://lucent-phoenix-95de8f.netlify.app/.netlify/functions/twikoo',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const runFn = () => {
    init();
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) anzhiyu.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else {
      loadTwikoo()
    }
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script><input type="hidden" name="page-type" id="page-type" value="post"></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://lucent-phoenix-95de8f.netlify.app/.netlify/functions/twikoo',
        region: '',
        pageSize: 6,
        includeReply: true
      }).then(function (res) {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        saveToLocal.set('twikoo-newest-comments', JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray)
      }).catch(function (err) {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.textContent= "无法获取评论，请确认相关配置是否正确"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      getScript('https://cdn.cbd.int/twikoo@1.6.39/dist/twikoo.all.min.js').then(runTwikoo)
    }
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'><div class='name'><span>${array[i].nick} </span></div></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <time datetime="${array[i].date}">${anzhiyu.diffDate(array[i].date, true)}</time></div>
        </div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom && ($dom.innerHTML= result)
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('twikoo-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script async data-pjax src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.1/bubble/bubble.js"></script><script>var visitorMail = "404@qq.com";
</script><script async data-pjax src="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><script src="/js/anzhiyu/right_click_menu.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.9/icon/ali_iconfont_css.css"><script id="click-heart" src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/dist/click-heart.min.js" async="async" mobile="false"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.cbd.int/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://cdn.cbd.int/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://cdn.cbd.int/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["meta[property=\"og:image\"]","meta[property=\"og:title\"]","meta[property=\"og:url\"]","meta[property=\"og:type\"]","meta[property=\"og:site_name\"]","meta[property=\"og:description\"]","head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]
var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  anzhiyu.removeGlobalFnEvent('pjax')
  anzhiyu.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script charset="UTF-8" src="https://cdn.cbd.int/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><div id="popup-window"><div class="popup-window-title">通知</div><div class="popup-window-divider"></div><div class="popup-window-content"><div class="popup-tip">你好呀</div><div class="popup-link"><i class="anzhiyufont anzhiyu-icon-arrow-circle-right"></i></div></div></div></body></html>